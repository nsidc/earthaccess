{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ba2387-54e8-4aa5-aedb-c7d90644536f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NASA Earthdata API Client üåç\n",
    "\n",
    "## Overview\n",
    "\n",
    "> TL;DR: **earthdata** is uses NASA APIs to search, preview and access NASA datasets on-prem and in the cloud with 4 lines of Python.\n",
    "\n",
    "There are many ways to access NASA datasets, we can use the Earthdata search portal. We can use DAAC specific portals or tools.\n",
    "We could even use data.gov! These web portals are great but... they are not designed for programmatic access and reproducible workflows. \n",
    "This is extremly important in the age of the cloud and reproducible open science.\n",
    "\n",
    "The good news is that NASA also exposes APIs that allows us to search, transform and access data in a programmatic way. \n",
    "There are already some very useful client libraries for these APIs:\n",
    "\n",
    "* python-cmr\n",
    "* eo-metadata-tools\n",
    "* harmony-py\n",
    "* Hyrax\n",
    "* others\n",
    "\n",
    "Each of these libraries has amazing features and some similarities but they miss the glue to take a researcher all the way from searching to getting the data. *Harmony-py* is probably the most complete client of the list and the future for cloud-based workflows but as of today it only serves a small number of datasets.\n",
    "\n",
    "\n",
    "### Data Formats and Cloud Access\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aed5ed-1f7b-46ac-b076-3278b5bc20cd",
   "metadata": {},
   "source": [
    "## Querying for data collections\n",
    "The DataCollection client can query CMR for any collection using all of CMR's Query parameters and has built-in accessors for the common ones.\n",
    "This makes it ideal for one liners and easier notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb1926-3442-446a-8a35-fcbba8868d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the classes from earthdata\n",
    "from earthdata import Auth, DataCollections, DataGranules, Accessor\n",
    "auth = Auth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5bf4c9-571b-4c93-af94-e66bd51cb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now search for collections using a pythonic API client for CMR.\n",
    "# Query = DataCollections(auth).keyword('fire').temporal(\"2016-01-01\", \"2020-12-12\")\n",
    "# Query = DataCollections(auth).keyword('GEDI').bounding_box(-134.7,58.9,-133.9,59.2)\n",
    "\n",
    "Query = DataCollections(auth).keyword('elevation').bounding_box(-134.7,58.9,-133.9,59.2)\n",
    "\n",
    "print(f'Collections found: {Query.hits()}')\n",
    "\n",
    "# filtering what UMM fields to print\n",
    "collections = Query.fields(['ShortName','Abstract']).get(10)\n",
    "# Inspect 5 results printing just the ShortName and Abstract\n",
    "collections[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5154c-f131-44ad-a68f-cf0fa21ce18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the results from DataCollections and DataGranules are enhanced python dict objects, we still can get all the fields from CMR\n",
    "collections[0][\"umm.ShortName\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d45a6f-ac37-4744-bcfe-88ac3dd6ac07",
   "metadata": {},
   "source": [
    "The DataCollections class returns python dictionaries with some handy methods.\n",
    "\n",
    "```python \n",
    "collection.concept_id() # returns the concept-id, used to search for data granules\n",
    "collection.abstract() # returns the abstract\n",
    "collection.landing_page() # returns the landing page if present in the UMM fields\n",
    "collection.get_data() # returns the portal where data can be accessed.\n",
    "```\n",
    "\n",
    "The same results can be obtained using the `dict` syntax:\n",
    "\n",
    "```python\n",
    "collection[\"meta\"][\"concept-id\"] # concept-id\n",
    "collection[\"umm\"][\"RelatedUrls\"] # URLs, with GET DATA, LANDING PAGE etc\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cdcd74-dfe3-4b83-93f4-7378a0d981df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now search for collections using a pythonic API client for CMR.\n",
    "# Query = DataCollections(auth).provider('POCLOUD')\n",
    "Query = DataCollections(auth).provider(\"POCLOUD\")\n",
    "\n",
    "print(f'Collections found: {Query.hits()}')\n",
    "collections = Query.fields(['ShortName']).get(20)\n",
    "# Printing 3 collections\n",
    "collections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c5a34a-e808-4cc9-b34d-353d091a8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the concept-id for the first 10 collections\n",
    "[collection.concept_id() for collection in collections[0:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb9c3bb-ac8b-48e8-8233-8c44da8fb7bc",
   "metadata": {},
   "source": [
    "## Querying for data granules\n",
    "\n",
    "The DataGranules class provides similar functionality as the collection class. To query for granules in a more reliable way concept-id would be the main key.\n",
    "You can search data granules using a short name but that could (more likely will) return different versions of the same data granules. \n",
    "\n",
    "In this example we're querying for 20 data grnaules from ICESat-2  [ATL03](https://nsidc.org/data/ATL03/versions/) version `003` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9364d737-5a79-4089-853f-76d2ad1c85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generally speaking we won't need the auth instance for queries to collections and granules\n",
    "# Query = DataGranules().short_name('ATL03').version(\"003\").bounding_box(-134.7,58.9,-133.9,59.2)\n",
    "\n",
    "Query = DataGranules(auth).short_name('ATL03').version(\"003\").bounding_box(-134.7,58.9,-133.9,59.2)\n",
    "granules = Query.get(20)\n",
    "print(granules[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aa8035-f4a8-4592-b19c-49d5c06331fb",
   "metadata": {},
   "source": [
    "## Pretty printting data granules\n",
    "\n",
    "Since we are in a notebook we can take advantage of it to see a moew user friendly version of the granules with the built-in function `display`\n",
    "This will render browse image for the granule if available and eventually will have a similar representation as the one from the Earthdata search portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd5f5c-a854-4a72-a831-33b8bd7ce9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing 2 granules using display\n",
    "[display(granule) for granule in granules[0:2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f32a4-026d-4a5f-af66-69026cabe966",
   "metadata": {},
   "source": [
    "### Spatiotemporal queries\n",
    "\n",
    "Our granules and collection classes accept the same spatial and temporal argumenst as CMR so we can search for granules that match spatiotemporal criteria.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa39ec-e2fb-49d1-bc54-8d8a2f0655aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = DataGranules().short_name(\"ATL03\").temporal(\"2020-03-01\", \"2020-03-30\").bounding_box(-134.7,58.9,-133.9,59.2).version(\"004\")\n",
    "print(f\"Granules found: {Query.hits()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c493585-0d48-41bb-8815-6c83ad20ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can print some info about these granules using the built-in methods\n",
    "granules = Query.get(4)\n",
    "data_links = [{'links': g.data_links(), 'size (MB):': g.size()} for g in granules]\n",
    "data_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3526f-4255-43e4-b5e2-7f926216e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More datasets to try\n",
    "\n",
    "# C1908348134-LPDAAC_ECS: GEDI L2A Elevation and Height Metrics Data Global Footprint Level V002\n",
    "# C1968980609-POCLOUD: Sentinel-6A MF Jason-CS L2 P4 Altimeter Low Resolution (LR) STC Ocean Surface Topography\n",
    "# C1575731655-LPDAAC_ECS: ASTER Global Digital Elevation Model NetCDF V003\n",
    "# Query = DataGranules(auth).short_name('ATL03').version(\"003\")\n",
    "Query = DataGranules(auth).short_name('ATL03').version(\"004\").bounding_box(-134.7,58.9,-133.9,59.2)\n",
    "# Query = DataGranules().concept_id(\"C1575731655-LPDAAC_ECS\").bounding_box(-134.7,58.9,-133.9,59.2)\n",
    "print(f\"Granules found: {Query.hits()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eafb81a-07da-439b-8daa-d23f55d6f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all granules have data previews, if they have the granule class will show up to 2 preview images while using Jupyter's display() function\n",
    "granules = Query.get(10)\n",
    "[display(g) for g in granules[0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09094e5-3974-40c0-a99f-99f59d383cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Granules are python dictionaries, with fancy nested key/value notation and some extra built-in methods.\n",
    "granules[0][\"umm.TemporalExtent.RangeDateTime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a344149-8718-4dc6-b962-75409318a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size in MB\n",
    "data_links = [{'links': g.data_links(), 'size (MB):': g.size()} for g in granules]\n",
    "data_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c90c43-6e17-42f5-8bf5-95fdd3cb0dce",
   "metadata": {},
   "source": [
    "## **Accessing the data**\n",
    "\n",
    "The cloud is not something magical, but having infrastructure on-demand is quite handy to have on many scientific workflows, especially if the data already lives in \"the cloud\".\n",
    "As for NASA, a data migration started in 2020 and will continue on the forseeable future. Not all but most of NASA data will be available on AWS object storage system or S3.\n",
    "\n",
    "To work with this data the first thing we need to do is to get the proper credentials for accessing data on their S3 buckets. These credentials are on a per-DAAC base and last a mere 1 hour. In the near future the Auth class will keep track of this to regenerate the credentials.\n",
    "\n",
    "With `earthdata` a researcher can get the files regardless if they are on-prem or cloud based with the same API call, although an important consideration is that if we want to access data in the cloud we must run the code in the cloud. This is because some S3 buckets are configured to only allow egress if the requester is in the same zone, `us-west-2`.\n",
    "\n",
    "## On-prem access  üì°\n",
    "\n",
    "DAAC hosted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b796fa53-60ac-4197-922d-1f6ee5dec00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to start the notebook from here we need to execute this cell and uncomment the lines below\n",
    "# Accessing not necessarily means downloading, specially in the cloud.\n",
    "from earthdata import Auth, DataGranules, DataCollections, Accessor\n",
    "auth = Auth()\n",
    "access = Accessor(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e4b90-f0e0-42e5-a4e2-d5444089161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = DataGranules(auth).concept_id(\"C1997321091-NSIDC_ECS\").bounding_box(-134.7,54.9,-100.9,69.2)\n",
    "print(f\"Granule hits: {Query.hits()}\")\n",
    "# getting more than 6,000 metadata records for demo purposes is going to slow us down a bit so let's get only 100\n",
    "granules = Query.get(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68779b52-8c14-438f-9427-50ce0038eb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "granule[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6090d-481d-4f80-acef-8d55be6bfaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does this granule belong to a cloud-based collection?\n",
    "granule[0].cloud_hosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ee4c9-5b8e-4633-aa7f-f323fd0ed283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the response is an array of dictionaries we can do pythonic things like ordering the granules by size\n",
    "import operator\n",
    "granules_by_size = sorted(granules, key=operator.itemgetter(\"size\"))\n",
    "# now our array is sorted by size from less to more. Let's print the first 10\n",
    "granules_by_size[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434466a3-602b-4dff-a260-f7db6901514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# accessing the data on prem means downloading it if we are in a local environment or \"uploading them\" if we are in the cloud.\n",
    "files = access.get(granules_by_size[0:3], \"./data/demo-atl03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe45fff-68ea-4f01-94c7-416d79cfd84c",
   "metadata": {},
   "source": [
    "## Cloud access ‚òÅÔ∏è\n",
    "\n",
    "Same API, just a different place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44403d51-0aa3-423c-8fff-e40d4969aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = DataGranules(auth).concept_id(\"C1968980609-POCLOUD\").bounding_box(-134.7,54.9,-100.9,69.2)\n",
    "print(f\"Granule hits: {Query.hits()}\")\n",
    "granules = Query.get(100)\n",
    "# is this a cloud hosted data granule?\n",
    "granules[0].cloud_hosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142739a4-409a-4d98-8978-43aa221b09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pretty print this\n",
    "granules[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3afc1a-145e-4084-9c93-dd9e1eff3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's order them by size again.\n",
    "import operator\n",
    "\n",
    "granules = Query.get(100)\n",
    "cloud_granules_by_size = sorted(granules, key=operator.itemgetter(\"size\"))\n",
    "# now our array is sorted by size from less to more. Let's print the first 10\n",
    "cloud_granules_by_size[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a294f1-b1f9-4cd4-8751-dfc32feacec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# If we get an error here, most likely is because we are running this code outside the us-west-2 region.\n",
    "files = access.get(cloud_granules_by_size[0:3], \"./data/demo-POCLOUD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f5f4f6-931a-43d2-80b2-f5a8ec4bd664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_mfdataset('./data/demo-POCLOUD/*.nc')\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276eca3-ca27-4970-9367-7e65e5f2302f",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "```python\n",
    "from earthdata import Auth, DataGranules, DataCollections, Accessor\n",
    "auth = Auth()\n",
    "access = Accessor(auth)\n",
    "\n",
    "Query = DataGranules(auth).concept_id(\"C1575731655-LPDAAC_ECS\").bounding_box(-134.7,58.9,-133.9,59.2)\n",
    "granules = Query.get(10)\n",
    "# preview the data granules\n",
    "granules \n",
    "# get the files\n",
    "files = access.get(granules)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**Wait, we said 4 lines of python, we meant 3!**\n",
    "\n",
    "```python\n",
    "\n",
    "from earthdata import Auth, DataGranules, DataCollections, Accessor\n",
    "auth = Auth()\n",
    "files = Accessor(auth).get(DataGranules().concept_id(\"C1575731655-LPDAAC_ECS\").bounding_box(-134.7,58.9,-133.9,59.2).get(10))\n",
    "\n",
    "# Profit!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1e550f-f6bc-4386-95ea-bd3723a6ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from earthdata import Auth, DataGranules, DataCollections, Accessor\n",
    "auth = Auth()\n",
    "files = Accessor(auth).get(DataGranules().concept_id(\"C1575731655-LPDAAC_ECS\").bounding_box(-134.7,58.9,-133.9,59.2).get(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d779e877-2f0c-4da2-92d5-6cc299204956",
   "metadata": {},
   "source": [
    "### Related links\n",
    "\n",
    "**CMR** API documentation: https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html\n",
    "\n",
    "**EDL** API documentation: https://urs.earthdata.nasa.gov/\n",
    "\n",
    "NASA OpenScapes: https://nasa-openscapes.github.io/earthdata-cloud-cookbook/\n",
    "\n",
    "NSIDC: https://nsidc.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
