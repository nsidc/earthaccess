{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ba2387-54e8-4aa5-aedb-c7d90644536f",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "# <img src=\"https://logos-world.net/wp-content/uploads/2020/05/NASA-Logo-1959-present.png\" width=\"100px\" align=\"middle\" /> Introducing NASA earthaccess üåç\n",
    "\n",
    "\n",
    "\n",
    "#### TL;DR: [**earthaccess**](https://github.com/nsidc/earthaccess) is a Python package to search, preview and access NASA datasets (on-prem or in the cloud) with a few lines of code.\n",
    "\n",
    "\n",
    "## Why? \n",
    "\n",
    "**Programmatic, Easy, Reproducible.**\n",
    "\n",
    "There are many ways to access NASA datasets, we can use the [Earthdata search portal](https://search.earthaccess.nasa.gov/). We can use DAAC specific portals or tools.\n",
    "We could even use [data.gov](https://data.gov)!  Web portals are great but they are not designed for programmatic access and reproducible workflows. This is extremely important in the age of the cloud and reproducible open science. \n",
    "\n",
    "The good news is that NASA also exposes APIs that allows us to search, transform and access data in a programmatic way. Many of these libraries contain amazing features and some similarities. In this context, **earthaccess** aims to be a simple library that can deal with the important parts of the metadata so we can access or download data without having to worry if a given dataset is on-prem or in the cloud.\n",
    "\n",
    "\n",
    "## How?\n",
    "\n",
    "> Note: There are a lot of acronyms that we need to get familiar with before any of this makes sense, here is a brief glossary for NASA Earthdata terms: [NASA glossary](glossary.md)\n",
    "\n",
    "\n",
    "### Authentication: Before we can use `earthaccess` we need an account with **[NASA EDL](https://urs.earthaccess.nasa.gov/)**\n",
    "\n",
    "\n",
    "Earthdata Login provides free and immediate access to thousands of EOSDIS data products covering all Earth science disciplines and topic areas for researchers, applied science users, application developers, and the general public.\n",
    "\n",
    "Once we have our NASA EDL login credentials we can start accessing NASA data in a programmatic way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f6c9ed-fe58-4e03-b29b-c6c447061f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "earthaccess.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95121ff7-5222-4778-a4de-25625e23884b",
   "metadata": {},
   "source": [
    "#### Auth()\n",
    "\n",
    "`earthaccess`'s **Auth** class provides 3 different strategies to authenticate ourselves with NASA EDL.\n",
    "\n",
    "* **netrc**: Do we have a `.netrc` file with our EDL credentials? if so, we can use it with `earthaccess`.\n",
    "If we don't have it and want to create one we can, earthaccess allows users to type their credentials and persist them into a `.netrc` file.\n",
    "\n",
    "```python\n",
    "auth = earthaccess.login(strategy=\"netrc\")\n",
    "```\n",
    "* **environment**: If we have our EDL credentials as environment variables \n",
    "  * EARTHDATA_USERNAME\n",
    "  * EARTHDATA_PASSWORD\n",
    "```python\n",
    "auth = earthaccess.login(strategy=\"environment\")\n",
    "```\n",
    "* **interactive**: We will be asked for our EDL credentials with optinal persistance to `.netrc`\n",
    "\n",
    "```python\n",
    "auth = earthaccess.login(strategy=\"interactive\", persist=True)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab3b4b-80cc-4790-9417-1dd12503aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# are we authenticated?\n",
    "\n",
    "auth = earthaccess.login(strategy=\"netrc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc8b461-8c68-4719-94e5-34057159dac7",
   "metadata": {},
   "source": [
    "## Querying for datasets\n",
    "\n",
    "The `DataCollections` class can query CMR for any collection (dataset) using all of CMR's Query parameters and has built-in functions to extract useful information from the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5bf4c9-571b-4c93-af94-e66bd51cb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step is to create a DataCollections query \n",
    "\n",
    "Query = earthaccess.collection_query()\n",
    "\n",
    "# Use chain methods to customize our query\n",
    "Query.keyword('elevation').bounding_box(-134.7,58.9,-133.9,59.2).temporal(\"2020-01-01\",\"2020-02-01\")\n",
    "\n",
    "print(f'Collections found: {Query.hits()}')\n",
    "\n",
    "# filtering what UMM fields to print, to see the full record we omit the fields filters\n",
    "# meta is always included as \n",
    "collections = Query.fields(['ShortName','Version']).get(5)\n",
    "# Inspect some results printing just the ShortName and Abstract\n",
    "collections[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26962664-cbe8-453f-b617-80d473df9c75",
   "metadata": {},
   "source": [
    "The results from a DataCollections and DataGranules query are enhanced python dictionaries, this means\n",
    "that we can access all the keys and values like we usually do with Python dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5154c-f131-44ad-a68f-cf0fa21ce18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections[0][\"umm\"][\"ShortName\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d45a6f-ac37-4744-bcfe-88ac3dd6ac07",
   "metadata": {},
   "source": [
    "The DataCollections class returns python dictionaries with some handy methods.\n",
    "\n",
    "```python \n",
    "collection.concept_id() # returns the concept-id, used to search for data granules\n",
    "collection.abstract() # returns the abstract\n",
    "collection.landing_page() # returns the landing page if present in the UMM fields\n",
    "collection.get_data() # returns the portal where data can be accessed.\n",
    "```\n",
    "\n",
    "The same results can be obtained using the `dict` syntax:\n",
    "\n",
    "```python\n",
    "collection[\"meta\"][\"concept-id\"] # concept-id\n",
    "collection[\"umm\"][\"RelatedUrls\"] # URLs, with GET DATA, LANDING PAGE etc\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cdcd74-dfe3-4b83-93f4-7378a0d981df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now search for collections using a pythonic API client for CMR.\n",
    "Query = earthaccess.collection_query().daac(\"PODAAC\")\n",
    "\n",
    "print(f'Collections found: {Query.hits()}')\n",
    "collections = Query.fields(['ShortName']).get(10)\n",
    "# Printing the first collection\n",
    "collections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63792353-ab3e-4f0b-963d-7750e4b89113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want cloud collections\n",
    "Query = earthaccess.collection_query().daac(\"PODAAC\").cloud_hosted(True)\n",
    "\n",
    "print(f'Collections found: {Query.hits()}')\n",
    "collections = Query.fields(['ShortName']).get(10)\n",
    "# Printing 3 collections\n",
    "collections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c5a34a-e808-4cc9-b34d-353d091a8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the concept-id for the first 10 collections\n",
    "[collection.concept_id() for collection in collections]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb9c3bb-ac8b-48e8-8233-8c44da8fb7bc",
   "metadata": {},
   "source": [
    "## Querying for data files (granules)\n",
    "\n",
    "The DataGranules class provides similar functionality as the collection class. To query for granules in a more reliable way concept-id would be the main key.\n",
    "You can search data granules using a short name but that could (more likely will) return different versions of the same data granules. \n",
    "\n",
    "In this example we're querying for 10 data grnaules from ICESat-2  [ATL06](https://nsidc.org/data/ATL06/versions/) version `005` dataset. \n",
    "\n",
    "\n",
    "> **Note**: Generally speaking we won't need authenticated queries unless they are restricted datasets for early adopters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9364d737-5a79-4089-853f-76d2ad1c85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# We build our query\n",
    "\n",
    "Query = earthaccess.granule_query().short_name('ATL06').version(\"005\").bounding_box(-134.7,58.9,-133.9,59.2)\n",
    "# We get 5 metadata records\n",
    "granules = Query.get(5)\n",
    "granules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aa8035-f4a8-4592-b19c-49d5c06331fb",
   "metadata": {},
   "source": [
    "## Pretty printing data granules\n",
    "\n",
    "Since we are in a notebook we can take advantage of it to see a more user friendly version of the granules with the built-in function `display`\n",
    "This will render browse image for the granule if available and eventually will have a similar representation as the one from the Earthdata search portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd5f5c-a854-4a72-a831-33b8bd7ce9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing 2 granules using display\n",
    "[display(granule) for granule in granules]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f32a4-026d-4a5f-af66-69026cabe966",
   "metadata": {},
   "source": [
    "### Spatiotemporal queries\n",
    "\n",
    "Our granules and collection classes accept the same spatial and temporal arguments as CMR so we can search for granules that match spatiotemporal criteria.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa39ec-e2fb-49d1-bc54-8d8a2f0655aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = earthaccess.granule_query().short_name(\"ATL06\").temporal(\"2020-03-01\", \"2020-03-30\").bounding_box(-134.7,58.9,-133.9,59.2).version(\"005\")\n",
    "# Always inspects the hits before retrieven the granule metadata, just because it's very verbose.\n",
    "print(f\"Granules found: {Query.hits()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c493585-0d48-41bb-8815-6c83ad20ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can print some info about these granules using the built-in methods\n",
    "granules = Query.get(5)\n",
    "data_links = [{'links': g.data_links(access=\"on_prem\"), 'size (MB):': g.size()} for g in granules]\n",
    "data_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c90c43-6e17-42f5-8bf5-95fdd3cb0dce",
   "metadata": {},
   "source": [
    "## **Accessing the data**\n",
    "\n",
    "With `earthaccess` a researcher can get the files regardless if they are on-prem or cloud based with the same API call, although an important consideration is that if we want to access data in the cloud (direct access) we must run the code in the cloud. This is because some S3 buckets are configured to only allow direct access (s3:// links) if the requester is in the same zone, `us-west-2`.\n",
    "\n",
    "## On-prem access: DAAC hosted data  üì°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239e041-db87-40d1-b81a-12c26e9e0a47",
   "metadata": {},
   "source": [
    "For this example we are going to use a PODAAC dataset `SMAP_JPL_L3_SSS_CAP_8DAY-RUNNINGMEAN_V5` which we previously queried (see querying for datasets) and got the concept id: `C1972955240-PODAAC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e4b90-f0e0-42e5-a4e2-d5444089161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "\n",
    "earthaccess.login()\n",
    "\n",
    "Query = earthaccess.granule_query().short_name(\"SMAP_JPL_L3_SSS_CAP_8DAY-RUNNINGMEAN_V5\").bounding_box(-134.7,54.9,-100.9,69.2)\n",
    "print(f\"Granule hits: {Query.hits()}\")\n",
    "# getting more than 6,000 metadata records for demo purposes is going to slow us down a bit so let's get only a few\n",
    "granules = Query.get(10)\n",
    "# Does this granule belong to a cloud-based collection?\n",
    "granules[0].cloud_hosted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436e8a72-64c5-4e6b-950b-ac801d7b926e",
   "metadata": {},
   "source": [
    "### Finally! let's get the data\n",
    "\n",
    "The Store class accepts the results from a `DataGranules()` query or it can also accept a list of URLs for the data files. In the second case we'll have to specify the DAAC since it cannot infer which credentials to use solely on the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434466a3-602b-4dff-a260-f7db6901514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "files = earthaccess.download(granules[0:4], \"./data/C1972955240-PODAAC/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe45fff-68ea-4f01-94c7-416d79cfd84c",
   "metadata": {},
   "source": [
    "## **Accessing the data in the cloud ‚òÅÔ∏è** \n",
    "<img src=\"https://www.freecodecamp.org/news/content/images/size/w2000/2020/08/Screenshot-2020-08-10-at-6.26.31-PM.png\" width=\"300px\" align=\"middle\" >\n",
    "\n",
    "\n",
    "\n",
    "With `earthaccess` a researcher can get the files regardless if they are on-prem or cloud based with the same API call, although an important consideration is that if we want to access data in the cloud we must run the code in the cloud. This is because some S3 buckets are configured to only allow direct access (s3:// links) if the requester is in the same zone, `us-west-2`.\n",
    "\n",
    "Same API, just a different place, in this case the `concept-id` for the same dataset is `C2208422957-POCLOUD`\n",
    "> Note: The `concept-id` changed even though is the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44403d51-0aa3-423c-8fff-e40d4969aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Query = earthaccess.granule_query().short_name(\"SMAP_JPL_L3_SSS_CAP_8DAY-RUNNINGMEAN_V5\").bounding_box(-134.7,54.9,-100.9,69.2)\n",
    "print(f\"Granule hits: {Query.hits()}\")\n",
    "results = Query.get(10)\n",
    "# is this a cloud hosted data granule?\n",
    "results[0].cloud_hosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59ca3e-b5d5-490f-b967-01d1c7b3fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pretty print this\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a294f1-b1f9-4cd4-8751-dfc32feacec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# we are running this code outside the us-west-2 region.\n",
    "try:\n",
    "    files = earthaccess.download(results[0:4], local_path=\"./data/demo-POCLOUD\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}, we are probably not using this code in the Amazon cloud. Trying external links...\")\n",
    "    # There is hope, even if we are not in the Amazon cloud we can still get the data\n",
    "    files = store.get(results[0:4], access=\"external\", local_path=\"./data/demo-POCLOUD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b91b45-7080-4257-8ccb-99f87c93b022",
   "metadata": {},
   "source": [
    "##  ‚òÅÔ∏è **Cloud Access Part II: streaming data**\n",
    "\n",
    "Being in the cloud allows us to stream data as if we were using it locally. Pairing gridded datasets on S3 and xarray isa very useful patter when we deal with a lot of data. \n",
    "\n",
    "> **Recommended read: [Skip the download! Stream NASA data directly into Python objects](https://medium.com/pangeo/intake-stac-nasa-4cd78d6246b7)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecdb529-5961-4fa6-b7e0-70bbd0d85041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import xarray as xr\n",
    "# data_links\n",
    "https_links = []\n",
    "s3_links = []\n",
    "\n",
    "fs = earthaccess.get_s3fs_session(provider='POCLOUD')\n",
    "\n",
    "for granule in results:\n",
    "    https_links.extend(granule.data_links(access=\"on_prem\"))\n",
    "    s3_links.extend(granule.data_links(access=\"direct\"))\n",
    "s3_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb71d7d-c77e-497b-9846-ba101e730457",
   "metadata": {},
   "source": [
    "### With earthaccess we can open URLS if we pass the provider or we can open the results directly and will derive the necessary credentials to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e693af6a-a80e-4ca2-a034-8da194c18aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ds_L3 = xr.open_mfdataset(\n",
    "    earthaccess.open(results[0:3]),\n",
    "    combine='nested',\n",
    "    concat_dim='time',\n",
    "    coords='minimal',\n",
    "    )\n",
    "ds_L3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276eca3-ca27-4970-9367-7e65e5f2302f",
   "metadata": {},
   "source": [
    "## Now to the important science! üöÄ \n",
    "\n",
    "### Recap\n",
    "\n",
    "```python\n",
    "\n",
    "import earthaccess\n",
    "\n",
    "# first we authenticate with NASA EDL\n",
    "auth = earthaccess.login()\n",
    "\n",
    "# Then we build a Query with spatiotemporal parameters\n",
    "GranuleQuery = earthaccess.granule_query().concept_id(\"C1575731655-LPDAAC_ECS\").bounding_box(-134.7,58.9,-133.9,59.2)\n",
    "\n",
    "# We get the metadata records from CMR\n",
    "granules = GranuleQuery.get()\n",
    "\n",
    "# Now it{s time to download (or open) our data granules list with get()\n",
    "files = earthaccess.download(granules, local_path='./data')\n",
    "\n",
    "# Now to the important science!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d779e877-2f0c-4da2-92d5-6cc299204956",
   "metadata": {},
   "source": [
    "### Related links\n",
    "\n",
    "**Github repository**: https://github.com/nsidc/earthaccess\n",
    "\n",
    "**CMR** API documentation: https://cmr.earthaccess.nasa.gov/search/site/docs/search/api.html\n",
    "\n",
    "**EDL** API documentation: https://urs.earthaccess.nasa.gov/\n",
    "\n",
    "NASA OpenScapes: https://nasa-openscapes.github.io/earthaccess-cloud-cookbook/\n",
    "\n",
    "NSIDC: https://nsidc.org\n",
    "\n",
    "\n",
    "Contact: luis.lopez@nsidc.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
